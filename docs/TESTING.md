# æµ‹è¯•æ¡†æ¶ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£æè¿°äº†levAnalyzeé¡¹ç›®æµ‹è¯•æ¡†æ¶çš„ä½¿ç”¨æ–¹æ³•ã€é…ç½®å’Œæœ€ä½³å®è·µã€‚

## ğŸ¯ æµ‹è¯•æ¡†æ¶æ¦‚è§ˆ

levAnalyzeæµ‹è¯•æ¡†æ¶æ˜¯ä¸€ä¸ªå¤šå±‚æ¬¡çš„æµ‹è¯•è§£å†³æ–¹æ¡ˆï¼ŒåŒ…å«ï¼š
- å•å…ƒæµ‹è¯•ï¼šæµ‹è¯•ç‹¬ç«‹æ¨¡å—åŠŸèƒ½
- é›†æˆæµ‹è¯•ï¼šæµ‹è¯•æ¨¡å—é—´åä½œ
- æ•°æ®è´¨é‡æµ‹è¯•ï¼šéªŒè¯æ•°æ®å®Œæ•´æ€§å’Œå‡†ç¡®æ€§
- æ€§èƒ½æµ‹è¯•ï¼šç›‘æ§æ€§èƒ½æŒ‡æ ‡
- CI/CDé›†æˆï¼šè‡ªåŠ¨åŒ–æµ‹è¯•æµç¨‹

## ğŸ“ æµ‹è¯•ç›®å½•ç»“æ„

```
tests/
â”œâ”€â”€ __init__.py                 # æµ‹è¯•æ¨¡å—åˆå§‹åŒ–
â”œâ”€â”€ conftest.py                # pytestå…¨å±€é…ç½®å’Œfixtures
â”œâ”€â”€ unit/                      # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_data_collectors.py
â”‚   â”œâ”€â”€ test_risk_calculators.py
â”‚   â”œâ”€â”€ test_signal_generators.py
â”‚   â””â”€â”€ test_utilities.py
â”œâ”€â”€ integration/               # é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ test_data_pipeline.py
â”‚   â””â”€â”€ test_api_endpoints.py
â”œâ”€â”€ data_quality/              # æ•°æ®è´¨é‡æµ‹è¯•
â”‚   â”œâ”€â”€ test_finra_data.py
â”‚   â”œâ”€â”€ test_fred_data.py
â”‚   â””â”€â”€ test_data_validation.py
â”œâ”€â”€ performance/               # æ€§èƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ test_calculation_speed.py
â”‚   â””â”€â”€ test_memory_usage.py
â”œâ”€â”€ fixtures/                  # æµ‹è¯•æ•°æ®fixtures
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ generators.py     # Mockæ•°æ®ç”Ÿæˆå™¨
â”‚   â””â”€â”€ __init__.py
â””â”€â”€ reports/                   # æµ‹è¯•æŠ¥å‘Šç›®å½•
    â”œâ”€â”€ coverage/
    â”œâ”€â”€ performance/
    â””â”€â”€ quality/
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è¿è¡Œæ‰€æœ‰æµ‹è¯•

```bash
# ä½¿ç”¨pytestç›´æ¥è¿è¡Œ
pytest tests/ -v

# ä½¿ç”¨è„šæœ¬è¿è¡Œ
./scripts/run-tests.sh

# ä½¿ç”¨Makefileè¿è¡Œ
make test
```

### 2. è¿è¡Œç‰¹å®šç±»å‹æµ‹è¯•

```bash
# å•å…ƒæµ‹è¯•
pytest tests/ -m unit

# é›†æˆæµ‹è¯•
pytest tests/ -m integration

# æ•°æ®è´¨é‡æµ‹è¯•
pytest tests/ -m data_quality

# æ€§èƒ½æµ‹è¯•
pytest tests/ -m performance
```

### 3. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š

```bash
# HTMLæµ‹è¯•æŠ¥å‘Š
pytest tests/ --html=test-report.html --self-contained-html

# è¦†ç›–ç‡æŠ¥å‘Š
pytest tests/ --cov=src --cov-report=html:htmlcov

# æ€§èƒ½åŸºå‡†æŠ¥å‘Š
pytest tests/ -m performance --benchmark-json=benchmark.json
```

## ğŸ”§ é…ç½®è¯´æ˜

### pytest.ini ä¸»é…ç½®

```ini
[tool:pytest]
# æµ‹è¯•å‘ç°è·¯å¾„
testpaths = tests
python_files = test_*.py *_test.py

# è¾“å‡ºé…ç½®
addopts =
    --strict-markers
    --verbose
    --cov=src
    --cov-report=term-missing
    --cov-fail-under=80

# æµ‹è¯•æ ‡è®°
markers =
    unit: å•å…ƒæµ‹è¯•
    integration: é›†æˆæµ‹è¯•
    data_quality: æ•°æ®è´¨é‡æµ‹è¯•
    performance: æ€§èƒ½æµ‹è¯•
    slow: æ…¢é€Ÿæµ‹è¯•
```

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# æµ‹è¯•ç¯å¢ƒ
export TESTING=true
export PYTHONPATH="${PWD}/src:${PYTHONPATH}"

# ç‰¹å®šæµ‹è¯•ç¯å¢ƒ
export UNIT_TEST=true
export INTEGRATION_TEST=true
export DATA_QUALITY_TEST=true
export PERFORMANCE_TEST=true
```

## ğŸ› ï¸ å¼€å‘å·¥å…·

### 1. é¢„æäº¤æ£€æŸ¥

```bash
# å®‰è£…pre-commit hooks
pre-commit install

# æ‰‹åŠ¨è¿è¡Œæ£€æŸ¥
pre-commit run --all-files
```

### 2. ä»£ç è´¨é‡å·¥å…·

```bash
# ä»£ç æ ¼å¼åŒ–
black src/ tests/
isort src/ tests/

# ä»£ç æ£€æŸ¥
flake8 src/ tests/
mypy src/

# å®‰å…¨æ£€æŸ¥
bandit -r src/
safety check
```

### 3. Dockeræµ‹è¯•ç¯å¢ƒ

```bash
# æ„å»ºæµ‹è¯•é•œåƒ
docker-compose -f docker-compose.test.yml build

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
docker-compose -f docker-compose.test.yml up --abort-on-container-exit test-runner

# è¿è¡Œç‰¹å®šæµ‹è¯•ç±»å‹
docker-compose -f docker-compose.test.yml up unit-tests
docker-compose -f docker-compose.test.yml up integration-tests
```

## ğŸ“Š Mockæ•°æ®ç”Ÿæˆ

é¡¹ç›®æä¾›äº†å®Œæ•´çš„Mockæ•°æ®ç”Ÿæˆå™¨ï¼Œç”¨äºæµ‹è¯•ç¯å¢ƒï¼š

```python
from tests.fixtures.data.generators import MockDataGenerator

# ç”ŸæˆFINRAèèµ„ä½™é¢æ•°æ®
finra_data = MockDataGenerator.generate_finra_margin_data(
    start_date="2020-01-01",
    periods=48,
    seed=42
)

# ç”ŸæˆS&P 500å¸‚åœºæ•°æ®
sp500_data = MockDataGenerator.generate_sp500_data(
    start_date="2020-01-01",
    periods=1096,
    seed=42
)

# ç”ŸæˆFREDç»æµæ•°æ®
fred_data = MockDataGenerator.generate_fred_data(
    start_date="2020-01-01",
    periods=48,
    seed=42
)

# ç”Ÿæˆè¾¹ç•Œæµ‹è¯•æ•°æ®
boundary_data = MockDataGenerator.generate_boundary_test_data()
```

## ğŸ” æµ‹è¯•æ ‡è®°ä½¿ç”¨

### pytestæ ‡è®°

```python
import pytest

@pytest.mark.unit
def test_single_function():
    """å•å…ƒæµ‹è¯•ç¤ºä¾‹"""
    pass

@pytest.mark.integration
def test_multiple_modules():
    """é›†æˆæµ‹è¯•ç¤ºä¾‹"""
    pass

@pytest.mark.data_quality
def test_data_integrity():
    """æ•°æ®è´¨é‡æµ‹è¯•ç¤ºä¾‹"""
    pass

@pytest.mark.performance
@pytest.mark.benchmark
def test_calculation_performance():
    """æ€§èƒ½æµ‹è¯•ç¤ºä¾‹"""
    pass

@pytest.mark.slow
def test_slow_operation():
    """æ…¢é€Ÿæµ‹è¯•ç¤ºä¾‹"""
    pass
```

### è¿è¡Œç‰¹å®šæ ‡è®°æµ‹è¯•

```bash
# åªè¿è¡Œå•å…ƒæµ‹è¯•
pytest tests/ -m unit

# è¿è¡Œå•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•
pytest tests/ -m "unit or integration"

# è·³è¿‡æ…¢é€Ÿæµ‹è¯•
pytest tests/ -m "not slow"

# åªè¿è¡Œå¿«é€Ÿèƒ½æµ‹è¯•
pytest tests/ -m "not slow and not performance"
```

## ğŸ“ˆ è¦†ç›–ç‡è¦æ±‚

é¡¹ç›®è¦æ±‚ç»´æŒé«˜ä»£ç è¦†ç›–ç‡ï¼š

- **æ•´ä½“è¦†ç›–ç‡**ï¼šâ‰¥85%
- **æ ¸å¿ƒç®—æ³•**ï¼šâ‰¥95%
- **æ•°æ®å¤„ç†æ¨¡å—**ï¼šâ‰¥90%
- **å·¥å…·å‡½æ•°**ï¼šâ‰¥80%

### ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š

```bash
# å‘½ä»¤è¡ŒæŠ¥å‘Š
pytest tests/ --cov=src --cov-report=term-missing

# HTMLæŠ¥å‘Š
pytest tests/ --cov=src --cov-report=html:htmlcov

# XMLæŠ¥å‘Š(ç”¨äºCIé›†æˆ)
pytest tests/ --cov=src --cov-report=xml
```

### æŸ¥çœ‹è¦†ç›–ç‡æŠ¥å‘Š

```bash
# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€HTMLæŠ¥å‘Š
open htmlcov/index.html

# æŸ¥çœ‹ç‰¹å®šæ¨¡å—è¦†ç›–ç‡
pytest src/data/processors/ --cov=src/data/processors --cov-report=term-missing
```

## âš¡ æ€§èƒ½æµ‹è¯•

### æ€§èƒ½åŸºå‡†æµ‹è¯•

```python
import pytest

@pytest.mark.performance
@pytest.mark.benchmark
def test_risk_calculation_performance(benchmark):
    """æ€§èƒ½æµ‹è¯•ç¤ºä¾‹"""
    result = benchmark(calculate_risk, test_data)
    assert result is not None
```

### å†…å­˜åˆ†æ

```bash
# å®‰è£…memory_profiler
pip install memory-profiler

# è¿è¡Œå†…å­˜åˆ†æ
python -m memory_profiler tests/performance/test_memory_usage.py

# ç”Ÿæˆå†…å­˜åˆ†ææŠ¥å‘Š
mprof run python -m pytest tests/ -m performance
mprof plot
```

## ğŸ› è°ƒè¯•æµ‹è¯•

### è°ƒè¯•å¤±è´¥æµ‹è¯•

```bash
# åœ¨ç¬¬ä¸€ä¸ªå¤±è´¥æ—¶åœæ­¢
pytest tests/ -x

# æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
pytest tests/ -v -s

# åœ¨è°ƒè¯•å™¨ä¸­è¿è¡Œ
pytest tests/ --pdb

# åªè¿è¡Œä¸Šæ¬¡å¤±è´¥çš„æµ‹è¯•
pytest tests/ --lf
```

### æµ‹è¯•è¾“å‡º

```bash
# æ˜¾ç¤ºæ‰“å°è¾“å‡º
pytest tests/ -s

# è¯¦ç»†å †æ ˆè·Ÿè¸ª
pytest tests/ --tb=long

# çŸ­å †æ ˆè·Ÿè¸ª
pytest tests/ --tb=short
```

## ğŸ”„ CI/CDé›†æˆ

### GitHub Actions

æµ‹è¯•æ¡†æ¶å·²é›†æˆåˆ°GitHub Actionsä¸­ï¼š

- **ä»£ç è´¨é‡æ£€æŸ¥**ï¼šæ¯æ¬¡pushå’ŒPR
- **å®‰å…¨æ‰«æ**ï¼šæ¯æ¬¡pushå’ŒPR
- **å¤šPythonç‰ˆæœ¬æµ‹è¯•**ï¼šPython 3.9-3.12
- **è‡ªåŠ¨åŒ–æŠ¥å‘Š**ï¼šè¦†ç›–ç‡ã€æ€§èƒ½ã€æµ‹è¯•ç»“æœ

### CIæµ‹è¯•å‘½ä»¤

```bash
# è¿è¡ŒCIæµ‹è¯•å¥—ä»¶
make ci-test

# è¿è¡Œå®Œæ•´CIç®¡é“
make ci-pipeline

# è¿è¡Œå®‰å…¨æ£€æŸ¥
make security
```

## ğŸ“ æµ‹è¯•æœ€ä½³å®è·µ

### 1. æµ‹è¯•å‘½å

```python
# å¥½çš„æµ‹è¯•å‘½å
def test_calculate_margin_debt_returns_correct_ratio():
    """æµ‹è¯•è®¡ç®—èèµ„å€ºåŠ¡æ¯”ç‡åŠŸèƒ½"""
    pass

# é¿å…çš„æµ‹è¯•å‘½å
def test_calc():
    pass
```

### 2. æµ‹è¯•ç»“æ„

```python
def test_vix_processor_data_validation():
    """æµ‹è¯•VIXå¤„ç†å™¨æ•°æ®éªŒè¯åŠŸèƒ½"""
    # Arrange: å‡†å¤‡æµ‹è¯•æ•°æ®
    test_data = MockDataGenerator.generate_vix_data()

    # Act: æ‰§è¡Œè¢«æµ‹è¯•åŠŸèƒ½
    processor = VIXProcessor()
    result = processor.validate_data(test_data)

    # Assert: éªŒè¯ç»“æœ
    assert result.is_valid is True
    assert len(result.errors) == 0
```

### 3. Mockä½¿ç”¨

```python
import pytest
from unittest.mock import Mock, patch

def test_external_api_call():
    """æµ‹è¯•å¤–éƒ¨APIè°ƒç”¨"""
    with patch('src.data.collectors.fred_api.get_data') as mock_get:
        # è®¾ç½®mockè¿”å›å€¼
        mock_get.return_value = {"value": 123.45}

        # æ‰§è¡Œæµ‹è¯•
        result = fetch_fred_data("GDP")

        # éªŒè¯ç»“æœ
        assert result == 123.45
        mock_get.assert_called_once_with("GDP")
```

### 4. å¼‚æ­¥æµ‹è¯•

```python
import pytest

@pytest.mark.asyncio
async def test_async_data_processing():
    """æµ‹è¯•å¼‚æ­¥æ•°æ®å¤„ç†"""
    processor = AsyncDataProcessor()
    result = await processor.process_async(test_data)
    assert result is not None
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å¯¼å…¥é”™è¯¯**
   ```bash
   export PYTHONPATH="${PWD}/src:${PYTHONPATH}"
   ```

2. **æƒé™é”™è¯¯**
   ```bash
   chmod +x scripts/run-tests.sh
   ```

3. **Dockeré—®é¢˜**
   ```bash
   docker-compose -f docker-compose.test.yml down
   docker system prune -f
   ```

4. **ä¾èµ–å†²çª**
   ```bash
   pip install --upgrade pip
   pip install -r requirements-test.txt
   ```

### è°ƒè¯•æŠ€å·§

```bash
# æŸ¥çœ‹pytestæ”¶é›†çš„æµ‹è¯•
pytest --collect-only

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest tests/unit/test_data_collectors.py

# è¿è¡Œç‰¹å®šæµ‹è¯•å‡½æ•°
pytest tests/unit/test_data_collectors.py::test_finra_data_fetch

# æ˜¾ç¤ºæµ‹è¯•é…ç½®
pytest --version
pytest --help
```

## ğŸ“š æ›´å¤šèµ„æº

- [pytestå®˜æ–¹æ–‡æ¡£](https://pytest.org/)
- [pytest-covè¦†ç›–ç‡æ–‡æ¡£](https://pytest-cov.readthedocs.io/)
- [pytest-benchmarkæ€§èƒ½æµ‹è¯•](https://pytest-benchmark.readthedocs.io/)
- [pre-commité’©å­æ–‡æ¡£](https://pre-commit.com/)
- [GitHub Actionsæ–‡æ¡£](https://docs.github.com/en/actions)